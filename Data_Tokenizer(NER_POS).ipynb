{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9fa060074c5348ac94b3abcfa623e987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9186204c2904b46b5bd5b608553e028",
              "IPY_MODEL_657ab27a27d84db8907224ca5c769146",
              "IPY_MODEL_914f0a4d489a49acb484ac16563cc5b1"
            ],
            "layout": "IPY_MODEL_f67dc6eae95c45d5b3b7b197fbbf7ac4"
          }
        },
        "e9186204c2904b46b5bd5b608553e028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31697abd82ef4065a401e473c47c08db",
            "placeholder": "​",
            "style": "IPY_MODEL_23ca46ad2d5d4a0b81d6832cd4bf7520",
            "value": "Map: 100%"
          }
        },
        "657ab27a27d84db8907224ca5c769146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7201526c7554437ba7ecb79b8e9be742",
            "max": 3250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ef1fe34c9f649889ba257bbf983ae96",
            "value": 3250
          }
        },
        "914f0a4d489a49acb484ac16563cc5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254606b9c6984f59a50d1dce022f6f8d",
            "placeholder": "​",
            "style": "IPY_MODEL_1b5644d3d935484fae8352607326e372",
            "value": " 3250/3250 [00:00&lt;00:00, 5594.26 examples/s]"
          }
        },
        "f67dc6eae95c45d5b3b7b197fbbf7ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31697abd82ef4065a401e473c47c08db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ca46ad2d5d4a0b81d6832cd4bf7520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7201526c7554437ba7ecb79b8e9be742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef1fe34c9f649889ba257bbf983ae96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "254606b9c6984f59a50d1dce022f6f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b5644d3d935484fae8352607326e372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.17"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJhsd3gAwUdY",
        "outputId": "c87a7759-40de-489c-cceb-4c39b7053f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.17 in /usr/local/lib/python3.10/dist-packages (4.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (2.31.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.1.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.17) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.17) (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp-wBRTe_cVk",
        "outputId": "1caaec42-8abe-443b-e39f-6111aee3856a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.17.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers) (0.1.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "gZK47Afu_gJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrX1tIce_gmi",
        "outputId": "6614974d-1b95-4064-ab93-fcaef443c09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H22_8j3_gpA",
        "outputId": "f5e0a09e-dcad-4434-ecf5-bb3fe517ba8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWsh2yo3_grn",
        "outputId": "859c8fe1-b4ed-4490-cd7a-cbb839eece02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "Rdo48Xpa_guM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = 'distilbert-base-cased'"
      ],
      "metadata": {
        "id": "f3KtwLgECkjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "pGTZbmy8CcB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(data['train'][0]['tokens'], is_split_into_words=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYa2LpANCcEZ",
        "outputId": "8de3fec1-4648-48d5-bee4-21718a47af7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGdnm0E7CcG3",
        "outputId": "a93a78eb-e86c-493d-eb3e-9e983f9fd33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOKukis7CcJc",
        "outputId": "28d004a0-e297-4379-faa7-4c1e40749f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': Value(dtype='string', id=None),\n",
              " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None),\n",
              " 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None),\n",
              " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'].features['ner_tags']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01SChAvBCcM_",
        "outputId": "a72b839c-5732-484d-a033-542f9495883e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'].features['ner_tags'].feature.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5rvbsdHEZ7b",
        "outputId": "d4f761f2-7c31-492a-e270-1658e7df5c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = data['train'].features['ner_tags'].feature.names"
      ],
      "metadata": {
        "id": "mAgvGjQ5EZ95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "t = tokenizer(data['train'][idx]['tokens'], is_split_into_words=True)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Incs6naEaAo",
        "outputId": "7ee7d5fc-a9e5-4115-db9b-b570fe3e9a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(t)\n",
        "# its not a dictionary, in fact an object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rlpyzq0hEaDD",
        "outputId": "9c2a95d2-a68c-4fe3-9f5e-e48e97ba966b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.tokens()\n",
        "\n",
        "#its a useful instance method .tokens()\n",
        "#here lamb is made into subwords\n",
        "#this situation is to be handled differently\n",
        "\n",
        "#the next task to wrap this into tokenize function that wraps up so that we can apply truncation\n",
        "# we then call the map function to map the tokenizer to our datasets\n",
        "#problem is that target is a sequence\n",
        "\n",
        "#by tokenization the input sequence may be more than target sequence, can be a problem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMURO5TmEaFV",
        "outputId": "7a367afe-9248-42e0-f4af-b27066a6cd28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'EU',\n",
              " 'rejects',\n",
              " 'German',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'British',\n",
              " 'la',\n",
              " '##mb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aligning targets to tokens"
      ],
      "metadata": {
        "id": "RL3HEWoasJVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For any word split into multiple tokens, we assign the same target\n",
        "\n",
        "la(5), ##mb(5)(repeat the same target again)\n",
        "\n",
        "This may called as EXPAND\n",
        "\n",
        "By this method the length of the input sequence will be equal to the target sequence"
      ],
      "metadata": {
        "id": "6Dgpx64BsY5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What about special tokens [CLS], [SEP] ?\n",
        "This tokens will also have to be accounted for as tokens\n",
        "\n",
        "Specifically the hugging face library uses integer value -100 for the outputs and targets that should be ignored\n",
        "\n",
        "A constant is taken because gradient will be 0, and there will be no weight upadation"
      ],
      "metadata": {
        "id": "R1jnGEV0tL8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algotrithm outline\n",
        "\n",
        "We have to loop through each word_id\n",
        "three scenarios\n",
        "1 - If word_id is None (label=-100)\n",
        "2 - IF word_id is integer (new word, grab a label for this word)\n",
        "3 If word_id is integer (repeated word, assign previous token)"
      ],
      "metadata": {
        "id": "TYLhfDSIxzsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IOB\n",
        "# B - beginning of an entity, I-inside of an entity, O-outside of entity\n",
        "\n",
        "# if \"Steve\" = [\"Ste\", \"ve\"]\n",
        "# we want [B-PER, I-PER]"
      ],
      "metadata": {
        "id": "CKFh0yN2EaU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG','B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
        "begin2inside = {\n",
        "    1:2,\n",
        "    3:4,\n",
        "    5:6,\n",
        "    7:8,\n",
        "}"
      ],
      "metadata": {
        "id": "DnFSllyMEDHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Align target function\n",
        "\n",
        "#def align_targets(labels, word_ids):\n",
        "#  aligned_labels=[]\n",
        "#  last_word=None\n",
        "#  for word in word_ids:\n",
        "#    if word is None:\n",
        "#      label=-100\n",
        "#    elif word != last_word:\n",
        "#      label=labels[word]\n",
        "#    else:\n",
        "#      label=labels[word]\n",
        "\n",
        "#    aligned_labels.append(label)\n",
        "#    last_word=word\n",
        "\n",
        "\n",
        "#  return aligned_labels\n"
      ],
      "metadata": {
        "id": "P9oC_IQuCcYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_targets(labels, word_ids):\n",
        "  aligned_labels=[]\n",
        "  last_word=None\n",
        "  for word in word_ids:\n",
        "    if word is None:\n",
        "      label=-100\n",
        "    elif word != last_word:\n",
        "      label=labels[word]\n",
        "    else:\n",
        "      label=labels[word]\n",
        "\n",
        "      if label in begin2inside:\n",
        "        label = begin2inside[label]\n",
        "\n",
        "    aligned_labels.append(label)\n",
        "    last_word=word\n",
        "\n",
        "\n",
        "  return aligned_labels"
      ],
      "metadata": {
        "id": "W6EgSl7JEDJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(batch):\n",
        "  tokenized_inputs = tokenizer(batch['tokens'], truncation=True, is_split_into_words=True)\n",
        "  labels_batch = batch['ner_tags']\n",
        "  aligned_label_batch = []\n",
        "  for i, labels in enumerate(labels_batch):\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "    aligned_label_batch.append(align_targets(labels,word_ids))\n",
        "  tokenized_inputs['labels'] = aligned_label_batch\n",
        "  return tokenized_inputs\n"
      ],
      "metadata": {
        "id": "Ol7zo8xeCcdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = data.map(tokenize_fn, batched=True, remove_columns=data['train'].column_names)"
      ],
      "metadata": {
        "id": "QdBsVeIf_gwU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9fa060074c5348ac94b3abcfa623e987",
            "e9186204c2904b46b5bd5b608553e028",
            "657ab27a27d84db8907224ca5c769146",
            "914f0a4d489a49acb484ac16563cc5b1",
            "f67dc6eae95c45d5b3b7b197fbbf7ac4",
            "31697abd82ef4065a401e473c47c08db",
            "23ca46ad2d5d4a0b81d6832cd4bf7520",
            "7201526c7554437ba7ecb79b8e9be742",
            "4ef1fe34c9f649889ba257bbf983ae96",
            "254606b9c6984f59a50d1dce022f6f8d",
            "1b5644d3d935484fae8352607326e372"
          ]
        },
        "outputId": "61b867e0-90f5-4b9e-bccf-5792466af99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fa060074c5348ac94b3abcfa623e987"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Target labels**"
      ],
      "metadata": {
        "id": "RGl_RZL8D5Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.tokens()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npa51WojskJK",
        "outputId": "1ade3d20-aaac-4d1f-ccf7-a36add77bc5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'EU',\n",
              " 'rejects',\n",
              " 'German',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'British',\n",
              " 'la',\n",
              " '##mb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.word_ids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGXOEoH-EDEe",
        "outputId": "d685afae-00b5-4fdf-e146-59b188ce5419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data['train'][idx]['ner_tags']\n",
        "word_ids = t.word_ids()\n",
        "aligned_targets = align_targets(labels, word_ids)\n",
        "aligned_targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-KCej6nEDMU",
        "outputId": "f4126ec2-cd42-48df-ec1a-3cdf614080a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aligned_labels = [label_names[t] if t>=0 else None for t in aligned_targets]\n",
        "for x, y in zip(t.tokens(), aligned_labels):\n",
        "  print(f\"{x}\\t{y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTtk1M6LKG7w",
        "outputId": "072bce9f-4554-4fff-8751-88b229a2b6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\tNone\n",
            "EU\tB-ORG\n",
            "rejects\tO\n",
            "German\tB-MISC\n",
            "call\tO\n",
            "to\tO\n",
            "boycott\tO\n",
            "British\tB-MISC\n",
            "la\tO\n",
            "##mb\tO\n",
            ".\tO\n",
            "[SEP]\tNone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# makeup a fake input just to test it\n",
        "\n",
        "words = ['[CLS]', 'Ger', '##man', 'call', 'to', 'boycott','Micro','##soft', '[SEP]']\n",
        "word_ids = [None, 0, 0, 1, 2, 3, 4, 4, None]\n",
        "labels = [7, 0, 0, 0, 3]\n",
        "aligned_targets = align_targets(labels, word_ids)\n",
        "aligned_labels = [label_names[t] if t>=0 else None for t in aligned_targets]\n",
        "\n",
        "for x, y in zip(words, aligned_labels):\n",
        "  print(f\"{x}\\t{y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hofSUIFcKG-C",
        "outputId": "bba503d5-7f04-4d8a-c3e8-e08c87e19467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\tNone\n",
            "Ger\tB-MISC\n",
            "##man\tI-MISC\n",
            "call\tO\n",
            "to\tO\n",
            "boycott\tO\n",
            "Micro\tB-ORG\n",
            "##soft\tI-ORG\n",
            "[SEP]\tNone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize both inputs and outputs\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "  tokenized_inputs = tokenizer(batch['tokens'], truncation=True, is_split_into_words=True)\n",
        "  labels_batch = batch['ner_tags']\n",
        "  aligned_labels_batch = []\n",
        "  for i, labels in enumerate(labels_batch):\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "    aligned_labels_batch.append(align_targets(labels, word_ids))\n",
        "  tokenized_inputs['labels'] = aligned_labels_batch\n",
        "\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "CTQ-BBojKHAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'].column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuDhg0YtKHDv",
        "outputId": "7ccc0885-e501-4861-8d00-5fd68bcf7940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = data.map(tokenize_fn, batched=True, remove_columns=data['train'].column_names)"
      ],
      "metadata": {
        "id": "d3xhB1LTEDO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SimEsJj8EDSe",
        "outputId": "f5a023cf-34da-4991-afc8-98c81836016a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Collater**\n",
        "# - *Padding is done per batch basis*\n",
        "# - This is handled by data collator\n"
      ],
      "metadata": {
        "id": "UJFCqGWkjCvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification"
      ],
      "metadata": {
        "id": "9INQHHXoskMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "ACFb8naIskPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['train'][0:2]"
      ],
      "metadata": {
        "id": "sZ8jIu3lskSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9675fbe9-47b7-4bf4-c7a9-ed4c2b556cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101,\n",
              "   7270,\n",
              "   22961,\n",
              "   1528,\n",
              "   1840,\n",
              "   1106,\n",
              "   21423,\n",
              "   1418,\n",
              "   2495,\n",
              "   12913,\n",
              "   119,\n",
              "   102],\n",
              "  [101, 1943, 14428, 102]],\n",
              " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]],\n",
              " 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100], [-100, 1, 2, -100]]}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# although we don't have to use data collator manually, we will see how it works"
      ],
      "metadata": {
        "id": "w6ehGPfviUVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[tokenized_datasets['train'][i] for i in range(2)]"
      ],
      "metadata": {
        "id": "ziJcthYKiUXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfefb294-5b78-440e-8b6b-49e2f7588607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input_ids': [101,\n",
              "   7270,\n",
              "   22961,\n",
              "   1528,\n",
              "   1840,\n",
              "   1106,\n",
              "   21423,\n",
              "   1418,\n",
              "   2495,\n",
              "   12913,\n",
              "   119,\n",
              "   102],\n",
              "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "  'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]},\n",
              " {'input_ids': [101, 1943, 14428, 102],\n",
              "  'attention_mask': [1, 1, 1, 1],\n",
              "  'labels': [-100, 1, 2, -100]}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator([tokenized_datasets['train'][i] for i in range(2)])"
      ],
      "metadata": {
        "id": "sIPh3PUNiUZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch['labels']"
      ],
      "metadata": {
        "id": "8cM2B1VriUdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f496c40a-38fa-42e4-fd11-f0b6dce0f5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
              "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Computing Metrics***"
      ],
      "metadata": {
        "id": "2VHVdvgXocCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What happens when we have multiple targets per sample\n",
        "\n",
        "#one solution - is to flatten all targtes or predictions into a single list and compute metrics if they are all a independent predictions"
      ],
      "metadata": {
        "id": "QSBMB9_ao9LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n",
        "\n",
        "# this library has the sole purpose of computing metrics of NLP tasks where the target is a sequence"
      ],
      "metadata": {
        "id": "CPn3ml0xiUhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84618f84-d408-49d5-982f-2ab32ba987b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "Ls4-csGDiUjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"seqeval\")"
      ],
      "metadata": {
        "id": "xNRrdfULiUl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a534bef-eefc-4306-ffb3-84a5f7728a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-e20ba34f8cc7>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this doesn't work\n",
        "\n",
        "# metric.compute(predictions=[1,0,0], references=[0,0,0])"
      ],
      "metadata": {
        "id": "H0aaxm0CszPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[['A', 'A', 'A']], references=[['A', 'B', 'A']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6J10JtwtDWK",
        "outputId": "82e14a1b-bf3c-49e4-d671-94e07e3bf307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: A seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall_precision': 0.0,\n",
              " 'overall_recall': 0.0,\n",
              " 'overall_f1': 0.0,\n",
              " 'overall_accuracy': 0.6666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[['O', 'O', 'I-ORG', 'B-MISC']], references=[['O', 'B-ORG', 'I-ORG', 'B-MISC']])"
      ],
      "metadata": {
        "id": "okMqwEKsiUnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b79f90-e16d-4047-f356-3213336f8fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
              " 'overall_precision': 0.5,\n",
              " 'overall_recall': 0.5,\n",
              " 'overall_f1': 0.5,\n",
              " 'overall_accuracy': 0.75}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metric(logits_and_labels):\n",
        "  logits, labels = logits_and_labels #both logits and labels are of shape nxt, where n is batch size, and t is sequence length\n",
        "  preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "  str_labels = [[label_names[t] for t in label if t != -100] for label in labels]\n",
        "\n",
        "  str_preds = [[label_names[p] for p, t in zip(pred, targ) if t != -100] for pred, targ in zip(preds, labels)]\n",
        "\n",
        "  # this is called double list comprehension\n",
        "  the_metrics = metric.compute(predictions=str_preds, references=str_labels)\n",
        "\n",
        "  return {\n",
        "      'precision' : the_metrics['overall_precision'],\n",
        "      'f1' : the_metrics['overall_f1'],\n",
        "      'recall' : the_metrics['overall_recall'],\n",
        "      'accuracy' : the_metrics['overall_accuracy']\n",
        "  }\n"
      ],
      "metadata": {
        "id": "qjJ95K0qo7gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Metrics**"
      ],
      "metadata": {
        "id": "cxIgj8cJvWjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {k:v for k, v in enumerate(label_names)}\n",
        "label2id = {v:k for k, v in id2label.items()}"
      ],
      "metadata": {
        "id": "WPgD_DMVo7if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model and Trainer**"
      ],
      "metadata": {
        "id": "ODRsWSkdxU7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification"
      ],
      "metadata": {
        "id": "cWbwjHFiqtV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOa_SwNZqtYY",
        "outputId": "9ec37fad-f2d5-474c-9365-e62ff7cdabd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "KGWVwEy5qtaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    'distilbert-finetuned-ner',\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    learning_rate = 2e-5,\n",
        "    num_train_epochs = 3,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "metadata": {
        "id": "iYbQ0AIrqtdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer"
      ],
      "metadata": {
        "id": "zo8mNlcQqtfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = tokenized_datasets['train'],\n",
        "    eval_dataset = tokenized_datasets['test'],\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = compute_metric,\n",
        "    tokenizer = tokenizer,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "-cnC2S0cqthw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "MC6Fs7ct_W23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "XVHrW51qqtjq",
        "outputId": "3991cdc5-acb6-423f-a067-17137f61f2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 14041\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5268\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5268/5268 05:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.103500</td>\n",
              "      <td>0.163226</td>\n",
              "      <td>0.855090</td>\n",
              "      <td>0.869747</td>\n",
              "      <td>0.884915</td>\n",
              "      <td>0.965349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.045700</td>\n",
              "      <td>0.181971</td>\n",
              "      <td>0.855252</td>\n",
              "      <td>0.873408</td>\n",
              "      <td>0.892351</td>\n",
              "      <td>0.966483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.026100</td>\n",
              "      <td>0.189059</td>\n",
              "      <td>0.862865</td>\n",
              "      <td>0.881109</td>\n",
              "      <td>0.900142</td>\n",
              "      <td>0.968280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3453\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to distilbert-finetuned-ner/checkpoint-1756\n",
            "Configuration saved in distilbert-finetuned-ner/checkpoint-1756/config.json\n",
            "Model weights saved in distilbert-finetuned-ner/checkpoint-1756/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-finetuned-ner/checkpoint-1756/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-finetuned-ner/checkpoint-1756/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3453\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to distilbert-finetuned-ner/checkpoint-3512\n",
            "Configuration saved in distilbert-finetuned-ner/checkpoint-3512/config.json\n",
            "Model weights saved in distilbert-finetuned-ner/checkpoint-3512/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-finetuned-ner/checkpoint-3512/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-finetuned-ner/checkpoint-3512/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3453\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to distilbert-finetuned-ner/checkpoint-5268\n",
            "Configuration saved in distilbert-finetuned-ner/checkpoint-5268/config.json\n",
            "Model weights saved in distilbert-finetuned-ner/checkpoint-5268/pytorch_model.bin\n",
            "tokenizer config file saved in distilbert-finetuned-ner/checkpoint-5268/tokenizer_config.json\n",
            "Special tokens file saved in distilbert-finetuned-ner/checkpoint-5268/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5268, training_loss=0.08062919089535284, metrics={'train_runtime': 306.2643, 'train_samples_per_second': 137.538, 'train_steps_per_second': 17.201, 'total_flos': 462023079274890.0, 'train_loss': 0.08062919089535284, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Save and Reload as Pipeline***"
      ],
      "metadata": {
        "id": "WeMK1wp-_cod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('my_saved_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvaNGZu9qtnH",
        "outputId": "42f649b3-2946-4c82-e77d-f19a7f42cf70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to my_saved_model\n",
            "Configuration saved in my_saved_model/config.json\n",
            "Model weights saved in my_saved_model/pytorch_model.bin\n",
            "tokenizer config file saved in my_saved_model/tokenizer_config.json\n",
            "Special tokens file saved in my_saved_model/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "i2Jc7aYNo7l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline('token-classification', model='my_saved_model', aggregation_strategy='simple', device=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-0oVMbP-A_z",
        "outputId": "eb336e6b-a56f-4b14-b9d8-372297fd6110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file my_saved_model/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"my_saved_model\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"B-PER\",\n",
            "    \"2\": \"I-PER\",\n",
            "    \"3\": \"B-ORG\",\n",
            "    \"4\": \"I-ORG\",\n",
            "    \"5\": \"B-LOC\",\n",
            "    \"6\": \"I-LOC\",\n",
            "    \"7\": \"B-MISC\",\n",
            "    \"8\": \"I-MISC\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"B-LOC\": 5,\n",
            "    \"B-MISC\": 7,\n",
            "    \"B-ORG\": 3,\n",
            "    \"B-PER\": 1,\n",
            "    \"I-LOC\": 6,\n",
            "    \"I-MISC\": 8,\n",
            "    \"I-ORG\": 4,\n",
            "    \"I-PER\": 2,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading configuration file my_saved_model/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"my_saved_model\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"B-PER\",\n",
            "    \"2\": \"I-PER\",\n",
            "    \"3\": \"B-ORG\",\n",
            "    \"4\": \"I-ORG\",\n",
            "    \"5\": \"B-LOC\",\n",
            "    \"6\": \"I-LOC\",\n",
            "    \"7\": \"B-MISC\",\n",
            "    \"8\": \"I-MISC\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"B-LOC\": 5,\n",
            "    \"B-MISC\": 7,\n",
            "    \"B-ORG\": 3,\n",
            "    \"B-PER\": 1,\n",
            "    \"I-LOC\": 6,\n",
            "    \"I-MISC\": 8,\n",
            "    \"I-ORG\": 4,\n",
            "    \"I-PER\": 2,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file my_saved_model/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
            "\n",
            "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at my_saved_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n",
            "Didn't find file my_saved_model/added_tokens.json. We won't load it.\n",
            "loading file my_saved_model/vocab.txt\n",
            "loading file my_saved_model/tokenizer.json\n",
            "loading file None\n",
            "loading file my_saved_model/special_tokens_map.json\n",
            "loading file my_saved_model/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner(\"Bill Gates of the CEO of Microsoft in Seattle, Washington\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjk08qif-BCY",
        "outputId": "595d6ee0-e03b-4096-c83e-3f620a5abaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9978424,\n",
              "  'word': 'Bill Gates',\n",
              "  'start': 0,\n",
              "  'end': 10},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9989512,\n",
              "  'word': 'Microsoft',\n",
              "  'start': 25,\n",
              "  'end': 34},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9992482,\n",
              "  'word': 'Seattle',\n",
              "  'start': 38,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.99904877,\n",
              "  'word': 'Washington',\n",
              "  'start': 47,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "daIShdKr-BFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DTvTzG-9iUrC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}